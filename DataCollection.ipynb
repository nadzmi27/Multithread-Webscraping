{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99cd47f-2aea-486e-9c6a-9671cdbe1a0b",
   "metadata": {},
   "source": [
    "# Data Collection for Australia Data Science Jobs\n",
    "In this notebook we will be scraping data from glassdoor **using Selenium** since glassdoor is a dynamic website. Scraping data from dynamic website is usually harder compared to static website as dynamic website require interaction to gather data. Futhermore, in this notebook I'll be using **threading** to increase the speed of webscraping by many-folds. \n",
    "\n",
    "Recommended resources:  \n",
    "- [Webscraping Tutorial (Youtube)](https://www.youtube.com/watch?v=RuNolAh_4bU)\n",
    "- [Multithreading Python (Youtube)](https://www.youtube.com/watch?v=NGLeprazvkM)\n",
    "- [Selenium Documentation](https://selenium-python.readthedocs.io/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10624ae-8056-4ac4-9285-3a35044ce448",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbdedc9-f929-49b9-bede-3187880e48b8",
   "metadata": {},
   "source": [
    "## Importing Library and Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9854fc3-46b0-4711-a141-98fd1366367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # for time delaying \n",
    "import pandas as pd # for dataframe\n",
    "from selenium import webdriver # to allow automation on webdriver (e.g. chrome, mozilla, edge)\n",
    "from selenium.webdriver.chrome.options import Options # to adjust the option of webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager # to use google chrome\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException # To handle error \n",
    "from selenium.webdriver.common.keys import Keys # to emulate keypress \n",
    "from selenium.webdriver.common.by import By # for finiding element\n",
    "import re # regex\n",
    "from tqdm.notebook import tqdm # track progress\n",
    "import threading # multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4189f1d-e23e-481b-be82-23a07d4d3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warning \n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('WDM').setLevel(logging.NOTSET)\n",
    "os.environ['WDM_LOG'] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fe1b8-7609-4110-a8d0-53a1256607e2",
   "metadata": {},
   "source": [
    "If we don't have driver installed, we can uncomment the following to add driver automatically. Can take a look [here](https://pypi.org/project/webdriver-manager/) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53c5d8bb-c086-4293-b141-837bd60a64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "# driver.set_window_size(1120, 1000)\n",
    "# options.add_argument('headless')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9a83f-f2d5-482b-b694-1c9c0c6161cf",
   "metadata": {},
   "source": [
    "## Defining Functions for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fb526d5-b3c5-4b48-b95d-57b7ff920992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_jobs(job_name, jobs_no = None, location = None, headless = True, driver_no = 4):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    chrome_options = None\n",
    "    if headless:\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "    main_driver = _collect_jobs(job_name, location, chrome_options)\n",
    "    \n",
    "    # Get number of pages\n",
    "    footer = main_driver.find_element(By.CLASS_NAME,'paginationFooter')\n",
    "    page_no = int(footer.text.split()[-1])\n",
    "    \n",
    "    # If number of jobs is specified only get upper(jobs_no/30) pages\n",
    "    if jobs_no is not None:\n",
    "        page_no = min(page_no, (jobs_no + 29)//30)\n",
    "    \n",
    "    lst = []\n",
    "    threads = []\n",
    "    for pn in tqdm(range(1, page_no + 1), desc = \"Page number\"):\n",
    "        current_url = main_driver.current_url\n",
    "        try:\n",
    "            next_page = main_driver.find_element(By.XPATH, '//div[@class=\"pageContainer\"]//span[@alt=\"next-icon\"]') \n",
    "            next_page.click()\n",
    "        except:\n",
    "            pass\n",
    "        t = threading.Thread(target = jobs_detail, args = (current_url,lst, chrome_options))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        if len(threads) == driver_no:            \n",
    "            threads.pop(0).join()\n",
    "            \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    return lst\n",
    "\n",
    "def _collect_jobs(job, location = None, option = None):  \n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(), options=option)\n",
    "    driver.set_window_size(1120, 1000)\n",
    "    # Go to glassdoor\n",
    "    driver.get('https://www.glassdoor.com.au/Job')\n",
    "    time.sleep(5)\n",
    "    # Get the search bar for job and location\n",
    "    search_job = driver.find_element(By.XPATH, '//*[@id=\"sc.keyword\"]')\n",
    "    search_location = driver.find_element(By.XPATH, '//*[@id=\"sc.location\"]')\n",
    "    \n",
    "    # If location is not defined, do nothing\n",
    "    if location is not None:\n",
    "        search_location.clear()\n",
    "        search_location.send_keys(location)\n",
    "    \n",
    "    # Find job\n",
    "    search_job.clear()\n",
    "    search_job.send_keys(job, Keys.RETURN)\n",
    "    \n",
    "    close_signup(driver)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def close_signup(driver):\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"MainCol\"]/div[1]/ul/li[1]').click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"JAModal\"]/div/div[2]/span').click()\n",
    "    except:\n",
    "#         print('No Signup')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5719afcd-e82b-4f39-93ff-0f2d44631e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_get_salary(job):\n",
    "    time.sleep(1)\n",
    "    temp = job.find_element(By.XPATH,'//div[contains(@class,\"salaryTab tabSection\")]/div[1]/div[1]')\n",
    "    if temp.text == \"Estimate provided by employer\":\n",
    "        temp = job.find_element(By.XPATH,'//div[contains(@class,\"salaryTab tabSection\")]/div[1]/div[2]')\n",
    "    sal = re.split('\\n|/', temp.text)\n",
    "    return (sal[0].strip(), sal[-2].strip(), sal[-1].strip()) # Estimate, Low, High\n",
    "\n",
    "# def job_get_desc(job):\n",
    "#     try:\n",
    "#         job.find_element(By.XPATH,'//*[@id=\"JobDescriptionContainer\"]/div[2][text()=\"Show More\"]').click()\n",
    "#     except:\n",
    "#         pass\n",
    "#     time.sleep(0.1)\n",
    "#     requirements = job.find_elements(By.XPATH, '//*[@class=\"jobDescriptionContent desc\"]//ul')\n",
    "#     job_descriptions = []\n",
    "#     for req in requirements:\n",
    "#         job_descriptions += req.text.split('\\n')\n",
    "#     return job_descriptions\n",
    "\n",
    "def job_get_desc(job):\n",
    "    \n",
    "    try:\n",
    "        job.find_element(By.XPATH,'//*[@id=\"JobDescriptionContainer\"]/div[2][text()=\"Show More\"]').click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(1)\n",
    "    requirements = job.find_element(By.XPATH, '//*[@class=\"jobDescriptionContent desc\"]')\n",
    "    return requirements.text\n",
    "\n",
    "def job_get_company_overview(job):\n",
    "    comp_size = comp_type = comp_sector = comp_founded = comp_industry = comp_revenue = -1\n",
    "    keyword = [\"Size\",\"Type\",\"Sector\", \"Founded\", \"Industry\", \"Revenue\"]\n",
    "    variables = [comp_size, comp_type, comp_sector, comp_founded, comp_industry, comp_revenue]\n",
    "    overview = job.find_element(By.XPATH, '//*[@id=\"EmpBasicInfo\"]//*[text()=\"Company Overview\"]/../div')\n",
    "    for var in range(len(keyword)):\n",
    "        try:\n",
    "            xp = './/*[text()=\"'+keyword[var]+'\"]/following-sibling::span'\n",
    "            variables[var] = overview.find_element(By.XPATH, xp).text\n",
    "        except:\n",
    "            pass\n",
    "    return variables\n",
    "\n",
    "def get_company_element(root, xp):\n",
    "    try:\n",
    "        result = root.find_element(By.XPATH, xp).text\n",
    "    except:\n",
    "        result = None\n",
    "    return result\n",
    "\n",
    "def get_company_ratings(job):\n",
    "    comp_rating = comp_rec_friend = comp_app_ceo = comp_rater = comp_car_opp = comp_compben = comp_cultval = comp_senmng = comp_wlb = None\n",
    "    try:\n",
    "        root = job.find_element(By.XPATH, '//*[@id=\"employerStats\"]/..')\n",
    "        \n",
    "        comp_rating = get_company_element(root, './/*[@data-test = \"rating-info\"]/div[1]')\n",
    "        comp_rec_friend = get_company_element(root,'.//*[text()=\"Recommend to a friend\"]/../div[1]')\n",
    "        comp_app_ceo = get_company_element(root, './/*[text()=\"Approve of CEO\"]/../div[1]')\n",
    "        comp_rater = get_company_element(root, './/*[text()=\"Recommend to a friend\"]/../div[1]/../../div[3]')\n",
    "        \n",
    "        try:\n",
    "            root = root.find_element(By.XPATH, './/span[text()=\"Career Opportunities\"]/..')\n",
    "            comp_car_opp = get_company_element(root, './span[3]')\n",
    "            comp_compben = get_company_element(root, './span[6]')\n",
    "            comp_cultval = get_company_element(root, './span[9]')\n",
    "            comp_senmng = get_company_element(root, './span[12]')\n",
    "            comp_wlb = get_company_element(root, './span[15]')\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass \n",
    "\n",
    "    return (comp_rating, comp_rec_friend, comp_app_ceo, comp_rater, comp_car_opp, comp_compben, comp_cultval, comp_senmng, comp_wlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9566549e-2aa5-4b00-801e-2011181d3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobs_detail(page_url, lst, option = None, driver = None):\n",
    "    time.sleep(2)\n",
    "    if driver == None:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options = option)\n",
    "        driver.set_window_size(1120, 1000)\n",
    "        \n",
    "    driver.get(page_url)\n",
    "    time.sleep(5)\n",
    "    close_signup(driver)\n",
    "    jobs = driver.find_elements(By.XPATH, '//*[@id=\"MainCol\"]/div[1]/ul/li')\n",
    "    _jobs_detail(lst, jobs)\n",
    "    driver.quit()\n",
    "\n",
    "def _jobs_detail(lst, jobs):\n",
    "    time.sleep(2)\n",
    "    for job in tqdm(jobs, desc = \"Jobs number\"):\n",
    "        job_title = -1\n",
    "        location = -1\n",
    "        company = -1\n",
    "        job_url = -1\n",
    "        job_descriptions = -1\n",
    "        # Salary\n",
    "        base_salary_estimate = base_salary_low = base_salary_high = -1\n",
    "        # Job overviews\n",
    "        comp_size = comp_type = comp_sector = comp_founded = comp_industry = comp_revenue = None\n",
    "        # Company ratings\n",
    "        comp_rating = comp_rec_friend = comp_app_ceo = comp_rater = comp_car_opp = comp_compben = comp_cultval = comp_senmng = comp_wlb = None\n",
    "        \n",
    "        # Get the job title, location, company name, job url\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            job_title =_get_attribute(job, 'data-normalize-job-title') \n",
    "        except: \n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            location = _get_attribute(job, 'data-job-loc')\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            job_child = job.find_element(By.XPATH,'div[1]/a')\n",
    "            company = _get_attribute(job_child, 'title')\n",
    "            job_url = _get_attribute(job_child, 'href')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        job_clicked = False\n",
    "        try:\n",
    "            job.click()\n",
    "            time.sleep(1)\n",
    "            job_clicked = True\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "            print(\"!\", end=\" \")\n",
    "            \n",
    "        if job_clicked:\n",
    "            # If there's no simplified title\n",
    "\n",
    "            if not isinstance(job_title, str):\n",
    "                time.sleep(1)\n",
    "                try:\n",
    "                    xp = '//*[@id=\"JDCol\"]/div/article/div/div[1]/div/div/div[1]/div[3]/div[1]/div[2]'\n",
    "                    job_title = job.find_element(By.XPATH, xp).text\n",
    "                    print(\"New Title:\", job_title, end=\" \")\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # Get the salary estimate\n",
    "            try:\n",
    "                (base_salary_estimate, base_salary_low, base_salary_high) = job_get_salary(job)\n",
    "            except:\n",
    "                print(\"No Salary Info\", end=\" \")\n",
    "            \n",
    "            # Get job description\n",
    "            try:\n",
    "                job_descriptions = job_get_desc(job)\n",
    "            except:\n",
    "                print(\"No Job Requirement Found\", end=\" \")\n",
    "                \n",
    "            # Get job overviews\n",
    "            try:\n",
    "                (comp_size, comp_type, comp_sector, comp_founded, comp_industry, comp_revenue) = job_get_company_overview(job)\n",
    "            except:\n",
    "                print(\"No Job overviews\", end=\" \")\n",
    "                \n",
    "            # Get company ratings\n",
    "            try:\n",
    "                ratings =  get_company_ratings(job)\n",
    "                (comp_rating, comp_rec_friend, comp_app_ceo, comp_rater, comp_car_opp, comp_compben, comp_cultval, comp_senmng, comp_wlb) = ratings\n",
    "            except:\n",
    "                print(\"No Ratings\", end=\" \")\n",
    "\n",
    "            lst.append({\n",
    "                \"Job Title\":job_title,\n",
    "                \"Job Location\": location,\n",
    "                \"Company\": company,\n",
    "                \"Url\":job_url,\n",
    "                \"Estimate Base Salary\" : base_salary_estimate,\n",
    "                \"Low Estimate\": base_salary_low,\n",
    "                \"High Estimate\": base_salary_high,\n",
    "                \"Company Size\" :comp_size, \n",
    "                \"Company Type\" : comp_type, \n",
    "                \"Company Sector\" : comp_sector, \n",
    "                \"Company Founded\" : comp_founded, \n",
    "                \"Company Industry\" : comp_industry, \n",
    "                \"Company Revenue\" : comp_revenue,\n",
    "                \"Job Descriptions\": job_descriptions,\n",
    "                \"Company Rating\" : comp_rating, \n",
    "                \"Company Friend Reccomendation\" : comp_rec_friend, \n",
    "                \"Company CEO Approval\" : comp_app_ceo, \n",
    "                \"Companny Number of Rater\" : comp_rater, \n",
    "                \"Company Career Opportinities\" :comp_car_opp, \n",
    "                \"Compensation and Benefits\" : comp_compben, \n",
    "                \"Company Culture and Values\" :comp_cultval, \n",
    "                \"Company Senior Management\" :comp_senmng, \n",
    "                \"Company Work Life Balance\" : comp_wlb\n",
    "                       })\n",
    "        \n",
    "def _get_attribute(job, attribute):\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        result = job.get_attribute(attribute)\n",
    "    except:\n",
    "        result = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59f2ccb-8d86-4bbf-a277-daadb87b6352",
   "metadata": {},
   "source": [
    "## Collecting Data\n",
    "This will take a really long time and not guaranteed to work 100%, I personally reccomend run it on location one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9254fe91-f868-4883-8315-dcba16a89e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [\"Victoria\", \"New South Wales\", \"Northern Territory\", \"Queensland\",\n",
    "          \"South Australia\", \"Tasmania\", \"Western Australia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d51e0a-37cb-4095-bd6a-439ad1d44552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loc in tqdm(locations, desc =\"States\"):\n",
    "#     jobs = collect_jobs(\"Data Science\", location = loc + \", Australia\")\n",
    "#     jobs_df = pd.DataFrame(jobs)\n",
    "#     jobs_df.to_csv(loc + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536c7511-8049-4c5f-888f-7230982798c8",
   "metadata": {},
   "source": [
    "## Testing (ignore these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56ced947-c02c-4782-b639-2d3187d46c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bb1dba3fc948bcac62913869fec7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5ccf1887b848788ddbb620b90bf3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Page number:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4777036c2954489695d775aa0b685085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Jobs number:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Job overviews "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7852e5174543c298f709780053727c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Jobs number:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Salary Info No Job overviews New Title: Navy Careers (No Experience Required) No Salary Info No Job Requirement Found No Job overviews ! No Salary Info ! ! ! No Salary Info ! ! ! ! ! No Salary Info ! No Salary Info No Salary Info ! ! ! "
     ]
    }
   ],
   "source": [
    "for loc in tqdm([\"Tasmania\"]):\n",
    "    jobs = collect_jobs(\"Data Science\", location = loc + \", Australia\")\n",
    "    jobs_df = pd.DataFrame(jobs)\n",
    "    jobs_df.to_csv(loc + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3721cc-5171-4502-afbf-9cc89ba6f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs = collect_jobs(\"Data Science\", 1, location =  \"Melbourne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb812a4-5595-4630-98c8-2784e97e7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in tqdm([\"New South Wales\"], desc =\"States\"):\n",
    "    jobs = collect_jobs(\"Data Science\", location = loc + \", Australia\")\n",
    "    jobs_df = pd.DataFrame(jobs)\n",
    "    jobs_df.to_csv(\"NSW.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
